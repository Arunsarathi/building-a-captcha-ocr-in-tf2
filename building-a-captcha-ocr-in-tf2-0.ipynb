{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version:  2.2.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "print(\"Tensorflow version: \", tf.__version__)\n",
    "\n",
    "seed = 1234\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images found:  1040\n",
      "Shape of image:  (50, 200, 3)\n",
      "Shape of image:  (50, 200, 3)\n",
      "Shape of image:  (50, 200, 3)\n",
      "Shape of image:  (50, 200, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x216 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Path to the data directory\n",
    "data_dir = Path(\"../input/captcha-version-2-images/samples/\")\n",
    "\n",
    "\n",
    "\n",
    "# Get list of all the images\n",
    "images = list(data_dir.glob(\"*.png\"))\n",
    "print(\"Number of images found: \", len(images))\n",
    "\n",
    "\n",
    "# Let's take a look at some samples first. \n",
    "# Always look at your data!\n",
    "sample_images = images[:4]\n",
    "\n",
    "_,ax = plt.subplots(2,2, figsize=(5,3))\n",
    "for i in range(4):\n",
    "    img = cv2.imread(str(sample_images[i]))\n",
    "    print(\"Shape of image: \", img.shape)\n",
    "    ax[i//2, i%2].imshow(img)\n",
    "    ax[i//2, i%2].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unqiue charcaters in the whole dataset:  19\n",
      "Maximum length of any captcha:  5\n",
      "Characters present:  ['2', '3', '4', '5', '6', '7', '8', 'b', 'c', 'd', 'e', 'f', 'g', 'm', 'n', 'p', 'w', 'x', 'y']\n",
      "Total number of samples in the dataset:  1040\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../input/captcha-version-2-images/samples/p7fy...</td>\n",
       "      <td>p7fyp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../input/captcha-version-2-images/samples/b5dn...</td>\n",
       "      <td>b5dn4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../input/captcha-version-2-images/samples/c2yn...</td>\n",
       "      <td>c2yn8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../input/captcha-version-2-images/samples/pnnw...</td>\n",
       "      <td>pnnwy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../input/captcha-version-2-images/samples/mwxw...</td>\n",
       "      <td>mwxwp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            img_path  label\n",
       "0  ../input/captcha-version-2-images/samples/p7fy...  p7fyp\n",
       "1  ../input/captcha-version-2-images/samples/b5dn...  b5dn4\n",
       "2  ../input/captcha-version-2-images/samples/c2yn...  c2yn8\n",
       "3  ../input/captcha-version-2-images/samples/pnnw...  pnnwy\n",
       "4  ../input/captcha-version-2-images/samples/mwxw...  mwxwp"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store all the characters in a set\n",
    "characters = set()\n",
    "\n",
    "# A list to store the length of each captcha\n",
    "captcha_length = []\n",
    "\n",
    "# Store image-label info\n",
    "dataset = []\n",
    "\n",
    "# Iterate over the dataset and store the\n",
    "# information needed\n",
    "for img_path in images:\n",
    "    # 1. Get the label associated with each image\n",
    "    label = img_path.name.split(\".png\")[0]\n",
    "    # 2. Store the length of this cpatcha\n",
    "    captcha_length.append(len(label))\n",
    "    # 3. Store the image-label pair info\n",
    "    dataset.append((str(img_path), label))\n",
    "    \n",
    "    # 4. Store the characters present\n",
    "    for ch in label:\n",
    "        characters.add(ch)\n",
    "\n",
    "# Sort the characters        \n",
    "characters = sorted(characters)\n",
    "\n",
    "# Convert the dataset info into a dataframe\n",
    "dataset = pd.DataFrame(dataset, columns=[\"img_path\", \"label\"], index=None)\n",
    "\n",
    "# Shuffle the dataset\n",
    "dataset = dataset.sample(frac=1.).reset_index(drop=True)\n",
    "\n",
    "\n",
    "print(\"Number of unqiue charcaters in the whole dataset: \", len(characters))\n",
    "print(\"Maximum length of any captcha: \", max(Counter(captcha_length).keys()))\n",
    "print(\"Characters present: \", characters)\n",
    "print(\"Total number of samples in the dataset: \", len(dataset))\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples:  936\n",
      "Number of validation samples:  104\n",
      "Number of training images:  (936, 50, 200)\n",
      "Number of training labels:  (936,)\n",
      "Number of validation images:  (104, 50, 200)\n",
      "Number of validation labels:  (104,)\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and validation sets\n",
    "training_data, validation_data = train_test_split(dataset, test_size=0.1, random_state=seed)\n",
    "\n",
    "training_data = training_data.reset_index(drop=True)\n",
    "validation_data = validation_data.reset_index(drop=True)\n",
    "\n",
    "print(\"Number of training samples: \", len(training_data))\n",
    "print(\"Number of validation samples: \", len(validation_data))\n",
    "\n",
    "\n",
    "\n",
    "# Map text to numeric labels \n",
    "char_to_labels = {char:idx for idx, char in enumerate(characters)}\n",
    "\n",
    "# Map numeric labels to text\n",
    "labels_to_char = {val:key for key, val in char_to_labels.items()}\n",
    "\n",
    "\n",
    "\n",
    "# Sanity check for corrupted images\n",
    "def is_valid_captcha(captcha):\n",
    "    for ch in captcha:\n",
    "        if not ch in characters:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "\n",
    "# Store arrays in memory as it's not a muvh big dataset\n",
    "def generate_arrays(df, resize=True, img_height=50, img_width=200):\n",
    "    \"\"\"Generates image array and labels array from a dataframe.\n",
    "    \n",
    "    Args:\n",
    "        df: dataframe from which we want to read the data\n",
    "        resize (bool)    : whether to resize images or not\n",
    "        img_weidth (int): width of the resized images\n",
    "        img_height (int): height of the resized images\n",
    "        \n",
    "    Returns:\n",
    "        images (ndarray): grayscale images\n",
    "        labels (ndarray): corresponding encoded labels\n",
    "    \"\"\"\n",
    "    \n",
    "    num_items = len(df)\n",
    "    images = np.zeros((num_items, img_height, img_width), dtype=np.float32)\n",
    "    labels = [0]*num_items\n",
    "    \n",
    "    for i in range(num_items):\n",
    "        img = cv2.imread(df[\"img_path\"][i])\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        if resize: \n",
    "            img = cv2.resize(img, (img_width, img_height))\n",
    "        \n",
    "        img = (img/255.).astype(np.float32)\n",
    "        label = df[\"label\"][i]\n",
    "        \n",
    "        # Add only if it is a valid captcha\n",
    "        if is_valid_captcha(label):\n",
    "            images[i, :, :] = img\n",
    "            labels[i] = label\n",
    "    \n",
    "    return images, np.array(labels)\n",
    "\n",
    "\n",
    "\n",
    "# Build training data\n",
    "training_data, training_labels = generate_arrays(df=training_data)\n",
    "print(\"Number of training images: \", training_data.shape)\n",
    "print(\"Number of training labels: \", training_labels.shape)\n",
    "\n",
    "\n",
    "# Build validation data\n",
    "validation_data, validation_labels = generate_arrays(df=validation_data)\n",
    "print(\"Number of validation images: \", validation_data.shape)\n",
    "print(\"Number of validation labels: \", validation_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    \"\"\"Generates batches from a given dataset.\n",
    "    \n",
    "    Args:\n",
    "        data: training or validation data\n",
    "        labels: corresponding labels\n",
    "        char_map: dictionary mapping char to labels\n",
    "        batch_size: size of a single batch\n",
    "        img_width: width of the resized\n",
    "        img_height: height of the resized\n",
    "        downsample_factor: by what factor did the CNN downsample the images\n",
    "        max_length: maximum length of any captcha\n",
    "        shuffle: whether to shuffle data or not after each epoch\n",
    "    Returns:\n",
    "        batch_inputs: a dictionary containing batch inputs \n",
    "        batch_labels: a batch of corresponding labels \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 data,\n",
    "                 labels,\n",
    "                 char_map,\n",
    "                 batch_size=16,\n",
    "                 img_width=200,\n",
    "                 img_height=50,\n",
    "                 downsample_factor=4,\n",
    "                 max_length=5,\n",
    "                 shuffle=True\n",
    "                ):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.char_map = char_map\n",
    "        self.batch_size = batch_size\n",
    "        self.img_width = img_width\n",
    "        self.img_height = img_height\n",
    "        self.downsample_factor = downsample_factor\n",
    "        self.max_length = max_length\n",
    "        self.shuffle = shuffle\n",
    "        self.indices = np.arange(len(data))    \n",
    "        self.on_epoch_end()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.data) / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # 1. Get the next batch indices\n",
    "        curr_batch_idx = self.indices[idx*self.batch_size:(idx+1)*self.batch_size]\n",
    "        \n",
    "        # 2. This isn't necessary but it can help us save some memory\n",
    "        # as not all batches the last batch may not have elements\n",
    "        # equal to the batch_size \n",
    "        batch_len = len(curr_batch_idx)\n",
    "        \n",
    "        # 3. Instantiate batch arrays\n",
    "        batch_images = np.ones((batch_len, self.img_width, self.img_height, 1),\n",
    "                               dtype=np.float32)\n",
    "        batch_labels = np.ones((batch_len, self.max_length), dtype=np.float32)\n",
    "        input_length = np.ones((batch_len, 1), dtype=np.int64) * \\\n",
    "                                (self.img_width // self.downsample_factor - 2)\n",
    "        label_length = np.zeros((batch_len, 1), dtype=np.int64)\n",
    "        \n",
    "        \n",
    "        for j, idx in enumerate(curr_batch_idx):\n",
    "            # 1. Get the image and transpose it\n",
    "            img = self.data[idx].T\n",
    "            # 2. Add extra dimenison\n",
    "            img = np.expand_dims(img, axis=-1)\n",
    "            # 3. Get the correpsonding label\n",
    "            text = self.labels[idx]\n",
    "            # 4. Include the pair only if the captcha is valid\n",
    "            if is_valid_captcha(text):\n",
    "                label = [self.char_map[ch] for ch in text]\n",
    "                batch_images[j] = img\n",
    "                batch_labels[j] = label\n",
    "                label_length[j] = len(text)\n",
    "        \n",
    "        batch_inputs = {\n",
    "                'input_data': batch_images,\n",
    "                'input_label': batch_labels,\n",
    "                'input_length': input_length,\n",
    "                'label_length': label_length,\n",
    "                }\n",
    "        return batch_inputs, np.zeros(batch_len).astype(np.float32)\n",
    "        \n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch size for training and validation\n",
    "batch_size = 16\n",
    "\n",
    "# Desired image dimensions\n",
    "img_width=200\n",
    "img_height=50 \n",
    "\n",
    "# Factor  by which the image is going to be downsampled\n",
    "# by the convolutional blocks\n",
    "downsample_factor=4\n",
    "\n",
    "# Maximum length of any captcha in the data\n",
    "max_length=5\n",
    "\n",
    "# Get a generator object for the training data\n",
    "train_data_generator = DataGenerator(data=training_data,\n",
    "                                     labels=training_labels,\n",
    "                                     char_map=char_to_labels,\n",
    "                                     batch_size=batch_size,\n",
    "                                     img_width=img_width,\n",
    "                                     img_height=img_height,\n",
    "                                     downsample_factor=downsample_factor,\n",
    "                                     max_length=max_length,\n",
    "                                     shuffle=True\n",
    "                                    )\n",
    "\n",
    "# Get a generator object for the validation data \n",
    "valid_data_generator = DataGenerator(data=validation_data,\n",
    "                                     labels=validation_labels,\n",
    "                                     char_map=char_to_labels,\n",
    "                                     batch_size=batch_size,\n",
    "                                     img_width=img_width,\n",
    "                                     img_height=img_height,\n",
    "                                     downsample_factor=downsample_factor,\n",
    "                                     max_length=max_length,\n",
    "                                     shuffle=False\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CTCLayer(layers.Layer):\n",
    "    def __init__(self, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.loss_fn = keras.backend.ctc_batch_cost\n",
    "\n",
    "    def call(self, y_true, y_pred, input_length, label_length):\n",
    "        # Compute the training-time loss value and add it\n",
    "        # to the layer using `self.add_loss()`.\n",
    "        loss = self.loss_fn(y_true, y_pred, input_length, label_length)\n",
    "        self.add_loss(loss)\n",
    "        \n",
    "        # On test time, just return the computed loss\n",
    "        return loss\n",
    "\n",
    "\n",
    "\n",
    "def build_model():\n",
    "    # Inputs to the model\n",
    "    input_img = layers.Input(shape=(img_width, img_height, 1),\n",
    "                            name='input_data',\n",
    "                            dtype='float32')\n",
    "    labels = layers.Input(name='input_label', shape=[max_length], dtype='float32')\n",
    "    input_length = layers.Input(name='input_length', shape=[1], dtype='int64')\n",
    "    label_length = layers.Input(name='label_length', shape=[1], dtype='int64')\n",
    "    \n",
    "    # First conv block\n",
    "    x = layers.Conv2D(32,\n",
    "               (3,3),\n",
    "               activation='relu',\n",
    "               kernel_initializer='he_normal',\n",
    "               padding='same',\n",
    "               name='Conv1')(input_img)\n",
    "    x = layers.MaxPooling2D((2,2), name='pool1')(x)\n",
    "    \n",
    "    # Second conv block\n",
    "    x = layers.Conv2D(64,\n",
    "               (3,3),\n",
    "               activation='relu',\n",
    "               kernel_initializer='he_normal',\n",
    "               padding='same',\n",
    "               name='Conv2')(x)\n",
    "    x = layers.MaxPooling2D((2,2), name='pool2')(x)\n",
    "    \n",
    "    # We have used two max pool with pool size and strides of 2.\n",
    "    # Hence, downsampled feature maps are 4x smaller. The number of\n",
    "    # filters in the last layer is 64. Reshape accordingly before\n",
    "    # passing it to RNNs\n",
    "    new_shape = ((img_width // 4), (img_height // 4)*64)\n",
    "    x = layers.Reshape(target_shape=new_shape, name='reshape')(x)\n",
    "    x = layers.Dense(64, activation='relu', name='dense1')(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    \n",
    "    # RNNs\n",
    "    x = layers.Bidirectional(layers.LSTM(128,\n",
    "                                         return_sequences=True,\n",
    "                                         dropout=0.2))(x)\n",
    "    x = layers.Bidirectional(layers.LSTM(64,\n",
    "                                         return_sequences=True,\n",
    "                                         dropout=0.25))(x)\n",
    "    \n",
    "    # Predictions\n",
    "    x = layers.Dense(len(characters)+1,\n",
    "              activation='softmax', \n",
    "              name='dense2',\n",
    "              kernel_initializer='he_normal')(x)\n",
    "    \n",
    "    # Calculate CTC\n",
    "    output = CTCLayer(name='ctc_loss')(labels, x, input_length, label_length)\n",
    "    \n",
    "    # Define the model\n",
    "    model = keras.models.Model(inputs=[input_img,\n",
    "                                       labels,\n",
    "                                       input_length,\n",
    "                                       label_length],\n",
    "                                outputs=output,\n",
    "                                name='ocr_model_v1')\n",
    "    \n",
    "    # Optimizer\n",
    "    sgd = keras.optimizers.SGD(learning_rate=0.002,\n",
    "                               decay=1e-6,\n",
    "                               momentum=0.9,\n",
    "                               nesterov=True,\n",
    "                               clipnorm=5)\n",
    "    \n",
    "    # Compile the model and return \n",
    "    model.compile(optimizer=sgd)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ocr_model_v1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_data (InputLayer)         [(None, 200, 50, 1)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Conv1 (Conv2D)                  (None, 200, 50, 32)  320         input_data[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 100, 25, 32)  0           Conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Conv2 (Conv2D)                  (None, 100, 25, 64)  18496       pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool2 (MaxPooling2D)            (None, 50, 12, 64)   0           Conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 50, 768)      0           pool2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 50, 64)       49216       reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 50, 64)       0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 50, 256)      197632      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 50, 128)      164352      bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "input_label (InputLayer)        [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_length (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "label_length (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 50, 20)       2580        bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "ctc_loss (CTCLayer)             (None, 1)            0           input_label[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 432,596\n",
      "Trainable params: 432,596\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "59/59 [==============================] - 4s 75ms/step - loss: 23.9489 - val_loss: 16.6406\n",
      "Epoch 2/50\n",
      "59/59 [==============================] - 2s 31ms/step - loss: 16.3946 - val_loss: 16.3878\n",
      "Epoch 3/50\n",
      "59/59 [==============================] - 2s 32ms/step - loss: 16.3738 - val_loss: 16.3556\n",
      "Epoch 4/50\n",
      "59/59 [==============================] - 2s 31ms/step - loss: 16.2333 - val_loss: 16.1007\n",
      "Epoch 5/50\n",
      "59/59 [==============================] - 2s 31ms/step - loss: 16.0150 - val_loss: 15.9768\n",
      "Epoch 6/50\n",
      "59/59 [==============================] - 2s 31ms/step - loss: 15.8745 - val_loss: 15.7452\n",
      "Epoch 7/50\n",
      "59/59 [==============================] - 2s 34ms/step - loss: 15.3758 - val_loss: 15.2441\n",
      "Epoch 8/50\n",
      "59/59 [==============================] - 2s 31ms/step - loss: 14.9937 - val_loss: 15.0506\n",
      "Epoch 9/50\n",
      "59/59 [==============================] - 2s 31ms/step - loss: 14.6899 - val_loss: 14.7527\n",
      "Epoch 10/50\n",
      "59/59 [==============================] - 2s 31ms/step - loss: 14.2140 - val_loss: 14.3314\n",
      "Epoch 11/50\n",
      "59/59 [==============================] - 2s 31ms/step - loss: 13.7794 - val_loss: 13.6185\n",
      "Epoch 12/50\n",
      "59/59 [==============================] - 2s 33ms/step - loss: 13.3840 - val_loss: 13.3399\n",
      "Epoch 13/50\n",
      "59/59 [==============================] - 2s 32ms/step - loss: 12.9667 - val_loss: 12.8525\n",
      "Epoch 14/50\n",
      "59/59 [==============================] - 2s 32ms/step - loss: 12.5765 - val_loss: 12.8396\n",
      "Epoch 15/50\n",
      "59/59 [==============================] - 2s 32ms/step - loss: 12.0831 - val_loss: 11.6899\n",
      "Epoch 16/50\n",
      "59/59 [==============================] - 2s 31ms/step - loss: 11.2656 - val_loss: 10.5463\n",
      "Epoch 17/50\n",
      "59/59 [==============================] - 2s 34ms/step - loss: 9.7826 - val_loss: 8.7846\n",
      "Epoch 18/50\n",
      "59/59 [==============================] - 2s 35ms/step - loss: 8.2135 - val_loss: 7.3270\n",
      "Epoch 19/50\n",
      "59/59 [==============================] - 2s 31ms/step - loss: 6.6533 - val_loss: 5.6784\n",
      "Epoch 20/50\n",
      "59/59 [==============================] - 2s 31ms/step - loss: 5.1979 - val_loss: 3.8107\n",
      "Epoch 21/50\n",
      "59/59 [==============================] - 2s 31ms/step - loss: 3.7716 - val_loss: 2.4213\n",
      "Epoch 22/50\n",
      "59/59 [==============================] - 2s 31ms/step - loss: 2.6297 - val_loss: 1.6326\n",
      "Epoch 23/50\n",
      "59/59 [==============================] - 2s 31ms/step - loss: 1.9202 - val_loss: 1.2347\n",
      "Epoch 24/50\n",
      "59/59 [==============================] - 2s 35ms/step - loss: 1.3784 - val_loss: 0.8166\n",
      "Epoch 25/50\n",
      "59/59 [==============================] - 2s 31ms/step - loss: 1.1253 - val_loss: 0.6964\n",
      "Epoch 26/50\n",
      "59/59 [==============================] - 2s 31ms/step - loss: 0.9585 - val_loss: 0.7855\n",
      "Epoch 27/50\n",
      "59/59 [==============================] - 2s 31ms/step - loss: 0.9367 - val_loss: 0.5468\n",
      "Epoch 28/50\n",
      "59/59 [==============================] - 2s 37ms/step - loss: 0.7401 - val_loss: 0.4065\n",
      "Epoch 29/50\n",
      "59/59 [==============================] - 2s 37ms/step - loss: 0.5460 - val_loss: 0.4493\n",
      "Epoch 30/50\n",
      "59/59 [==============================] - 2s 35ms/step - loss: 0.5018 - val_loss: 0.2926\n",
      "Epoch 31/50\n",
      "59/59 [==============================] - 2s 32ms/step - loss: 0.4654 - val_loss: 0.2313\n",
      "Epoch 32/50\n",
      "59/59 [==============================] - 2s 32ms/step - loss: 0.3659 - val_loss: 0.1056\n",
      "Epoch 33/50\n",
      "59/59 [==============================] - 2s 32ms/step - loss: 0.2801 - val_loss: 0.0865\n",
      "Epoch 34/50\n",
      "59/59 [==============================] - 2s 34ms/step - loss: 0.2568 - val_loss: 0.1718\n",
      "Epoch 35/50\n",
      "59/59 [==============================] - 2s 35ms/step - loss: 0.3038 - val_loss: 0.0779\n",
      "Epoch 36/50\n",
      "59/59 [==============================] - 2s 31ms/step - loss: 0.1896 - val_loss: 0.0714\n",
      "Epoch 37/50\n",
      "59/59 [==============================] - 2s 30ms/step - loss: 0.1917 - val_loss: 0.1426\n",
      "Epoch 38/50\n",
      "59/59 [==============================] - 2s 30ms/step - loss: 0.1609 - val_loss: 0.0369\n",
      "Epoch 39/50\n",
      "59/59 [==============================] - 2s 31ms/step - loss: 0.1234 - val_loss: 0.0194\n",
      "Epoch 40/50\n",
      "59/59 [==============================] - 2s 30ms/step - loss: 0.1665 - val_loss: 0.0446\n",
      "Epoch 41/50\n",
      "59/59 [==============================] - 2s 34ms/step - loss: 0.1032 - val_loss: 0.0235\n",
      "Epoch 42/50\n",
      "59/59 [==============================] - 2s 30ms/step - loss: 0.1143 - val_loss: 0.0082\n",
      "Epoch 43/50\n",
      "59/59 [==============================] - 2s 30ms/step - loss: 0.0626 - val_loss: 0.0356\n",
      "Epoch 44/50\n",
      "59/59 [==============================] - 2s 30ms/step - loss: 0.0840 - val_loss: 0.0516\n",
      "Epoch 45/50\n",
      "59/59 [==============================] - 2s 31ms/step - loss: 0.0674 - val_loss: 0.0221\n",
      "Epoch 46/50\n",
      "59/59 [==============================] - 2s 32ms/step - loss: 0.0680 - val_loss: 0.0330\n",
      "Epoch 47/50\n",
      "59/59 [==============================] - 2s 35ms/step - loss: 0.0345 - val_loss: 0.0509\n"
     ]
    }
   ],
   "source": [
    "# Add early stopping\n",
    "es = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                   patience=5,\n",
    "                                   restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_data_generator,\n",
    "                    validation_data=valid_data_generator,\n",
    "                    epochs=50,\n",
    "                    callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_data (InputLayer)      [(None, 200, 50, 1)]      0         \n",
      "_________________________________________________________________\n",
      "Conv1 (Conv2D)               (None, 200, 50, 32)       320       \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling2D)         (None, 100, 25, 32)       0         \n",
      "_________________________________________________________________\n",
      "Conv2 (Conv2D)               (None, 100, 25, 64)       18496     \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling2D)         (None, 50, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 50, 768)           0         \n",
      "_________________________________________________________________\n",
      "dense1 (Dense)               (None, 50, 64)            49216     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 50, 64)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 50, 256)           197632    \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 50, 128)           164352    \n",
      "_________________________________________________________________\n",
      "dense2 (Dense)               (None, 50, 20)            2580      \n",
      "=================================================================\n",
      "Total params: 432,596\n",
      "Trainable params: 432,596\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "prediction_model = keras.models.Model(model.get_layer(name='input_data').input,\n",
    "                                        model.get_layer(name='dense2').output)\n",
    "prediction_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A utility to decode the output of the network\n",
    "def decode_batch_predictions(pred):\n",
    "    pred = pred[:, :-2]\n",
    "    input_len = np.ones(pred.shape[0])*pred.shape[1]\n",
    "    \n",
    "    # Use greedy search. For complex tasks, you can use beam search\n",
    "    results = keras.backend.ctc_decode(pred, \n",
    "                                        input_length=input_len,\n",
    "                                        greedy=True)[0][0]\n",
    "    \n",
    "    # Iterate over the results and get back the text\n",
    "    output_text = []\n",
    "    for res in results.numpy():\n",
    "        outstr = ''\n",
    "        for c in res:\n",
    "            if c < len(characters) and c >=0:\n",
    "                outstr += labels_to_char[c]\n",
    "        output_text.append(outstr)\n",
    "    \n",
    "    # return final text results\n",
    "    return output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth: 8npe3 \t Predicted: 8npe3\n",
      "Ground truth: ndme7 \t Predicted: ndme7\n",
      "Ground truth: 64m82 \t Predicted: 64m82\n",
      "Ground truth: 38n57 \t Predicted: 38n57\n",
      "Ground truth: myf82 \t Predicted: myf82\n",
      "Ground truth: ewnx8 \t Predicted: ewnx8\n",
      "Ground truth: bnc5f \t Predicted: bnc5f\n",
      "Ground truth: 53mn8 \t Predicted: 53mn8\n",
      "Ground truth: 28348 \t Predicted: 28348\n",
      "Ground truth: g842c \t Predicted: g842c\n",
      "Ground truth: x4gg5 \t Predicted: x4gg5\n",
      "Ground truth: mggce \t Predicted: mggce\n",
      "Ground truth: bd3b7 \t Predicted: bd3b7\n",
      "Ground truth: yw7ny \t Predicted: yw7ny\n",
      "Ground truth: b6f2p \t Predicted: b6f2p\n",
      "Ground truth: fwxdp \t Predicted: fwxdp\n"
     ]
    }
   ],
   "source": [
    "#  Let's check results on some validation samples\n",
    "for p, (inp_value, _) in enumerate(valid_data_generator):\n",
    "    bs = inp_value['input_data'].shape[0]\n",
    "    X_data = inp_value['input_data']\n",
    "    labels = inp_value['input_label']\n",
    "    \n",
    "    preds = prediction_model.predict(X_data)\n",
    "    pred_texts = decode_batch_predictions(preds)\n",
    "    \n",
    "    \n",
    "    orig_texts = []\n",
    "    for label in labels:\n",
    "        text = ''.join([labels_to_char[int(x)] for x in label])\n",
    "        orig_texts.append(text)\n",
    "        \n",
    "    for i in range(bs):\n",
    "        print(f'Ground truth: {orig_texts[i]} \\t Predicted: {pred_texts[i]}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please upvote if you liked the notebook.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
